{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: For Beginners, By Beginners\n",
    "adpated from Emil Krumov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "So, neural nets. It’s the first thing that pops up in the minds of most of the common coders when they hear the buzzwords artificial intelligence and/or machine learning. Although not being the most fundamental material in the book, it is actually a not so bad starting point if explained in a beginner-friendly language.\n",
    "\n",
    "Throughout this article I will take you on a journey starting from the very beginning of the neural networks ideology, take you through the core modern principles that make it learn, and finally show you a step-by-step implementation of a neural network model from scratch featuring Fully Connected, Activation, Flatten, Convolution and Pooling layers. This implementation is heavily based on and inspired by this amazing article by\n",
    "Omar Aflak\n",
    "which is a must-read for everyone who wants to learn more on the mathematical background of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Neural Networks\n",
    "\n",
    "The history of neural networks traces back to 1943 when neurophysiologist Warren McCulloch and mathematician Walter Pitts portrayed a model of a human brain neuron with a simple electronic circuit which took a set of inputs, multiplied them by weighted values and put them through a threshold gate which gave as output a value of 0 or 1, based on the threshold value. This model was called the McCulloch-Pitts perceptron.\n",
    "\n",
    "<img src=\"perceptron.gif\" width=350 height=350 />\n",
    "Image source: wikimedia commons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea was taken further by a psychologist called Rosenblatt who created the mathematical model of the perceptron and called it Mark I Perceptron. It was based on the McCulloch-Pitts model and was one of the first attempts to make a machine learn. The perceptron model also took a set of binary inputs which were then multiplied by weighted values(representing the synapse strength). Then a bias typically having a value of 1 was added(an offset that ensures that more functions are computable with the same input) and once again the output was set to 0 or 1 based on a threshold value. The input mentioned above is either the input data or other perceptrons’ outputs.\n",
    "\n",
    "While the McCulloch-Pitts model was a groundbreaking research at that time, it lacked a good mechanism of learning which made it unsuitable for the area of AI.\n",
    "\n",
    "Rosenblatt took inspiration from Donald Hebb’s thesis that learning occurred in the human brain through formation and change of synapses between neurons and then came up with the idea to replicate it in its own way. He thought of a perceptron which takes a training set of input-output examples and forms(learns) a function by changing the weights of the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The implementation took four steps:\n",
    "\n",
    "1.  Initialize a perceptron with random weights\n",
    "2.  For each example in the training set, compute the output\n",
    "3.  If the output should have been 1 but was 0 instead, increase the weights with input 1 and vice-versa — if the output is 1 but should’ve been 0, decrease the weights with input of 1.\n",
    "4.  Repeat steps 2–4 for each example until the perceptron outputs correct values\n",
    "\n",
    "This set of instructions are what modern perceptrons are based on. Due to significant increase of computing power however, we can now work with many more perceptrons grouped together forming a neural network.\n",
    "\n",
    "<img src=\"schem_of_perceptron_classifier.webp\" width=350 height=350 />\n",
    "Image source: mixtend\n",
    "\n",
    "However, they are not just randomly put in the network but are actually part of another building block — a layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "A layer is made of perceptrons which are linked to the perceptrons of the previous and the next layers if such do happen to exist. Every layer defines it’s own functionality and therefore serves its own purpose. Neural networks consist of an input layer(takes the initial data), an output layer(returns the overall result of the network), and hidden layers(one or many layers with different sizes(number of perceptrons) and functionality).\n",
    "\n",
    "<img src=\"layers.webp\" width=350 height=350 />\n",
    "Source: cs231n.github.io\n",
    "\n",
    "In order for the network to be able to learn and produce results each layer has to implement two functions — forward propagation and backward propagation(shortly backpropagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Class\n",
    "\n",
    "class Layer:\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.input = None\n",
    "    self.output = None\n",
    "    \n",
    "  def forward_propagation(self, input):\n",
    "    raise NotImplementedError\n",
    "    \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a train travelling between point A(input) and point B(output) which changes direction each time it reaches one of the points. The A to B course takes one or more samples from the input layer and carries it through the forward propagation functions of all hidden layers consecutively, until point B is reached(and a result is produced). Backpropagation is basically the same thing only in the opposite direction — the course takes the data through the backpropagation methods of all layers in a reverse order until it reaches point A. What differs the two courses though is what happens inside of these methods.\n",
    "\n",
    "Forward propagation is only responsible for running the input through a function and return the result. No learning, only calculations. Backpropagation is a bit trickier because it is responsible for doing two things:\n",
    "\n",
    "* Update the parameters of the layer in order to improve the accuracy of the forward propagation method.\n",
    "* Implement the derivative of the forward propagation function and return the result.\n",
    "\n",
    "So how and why does that happen exactly. The mystery unravels at point B — before the train changes direction and goes through the backpropagation of all the layers. In order to tune our model we need to answer two questions:\n",
    "\n",
    "* How good the model’s result is compared with the actual output?\n",
    "* How do we minimize this difference?\n",
    "\n",
    "The process of answering the first question is known as calculating the error. To do that we use cost functions(synonyms with loss functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ MSE = \\frac{1}{n} \\sum_{i=0}^{N} (y_{Ei} - y_{Pi})^2$\n",
    "Mean Squared Error(MSE) between expected (E) and predicted (P) values also called the sum of squared residuals. \n",
    "(This is the reduced $\\chi^2$ statistic with the individual errors, $\\sigma_i$ set to one)\n",
    "\n",
    "It is a pretty straightforward function — we sum the squares of the difference between the actual output and the model’s output and we calculate the mean. But to help our model implementing MSE only isn’t going to be of any significant help. We must implement its derivative as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred):    \n",
    "  return np.mean((y - y_pred)**2)\n",
    "\n",
    "def mse_prime(y, y_pred):\n",
    "  return 2 * (y_pred - y) / y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\vec{F} = -\\vec{\\nabla{\\phi}}$\n",
    "\n",
    "$\\vec{F} = -\\frac{\\partial \\phi}{\\partial x}\\hat{i}+\\frac{\\partial \\phi}{\\partial y}\\hat{j}+\\frac{\\partial \\phi}{\\partial z}\\hat{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But why do we need this? Because of the infamous…\n",
    "## Gradient Descent\n",
    "\n",
    "The last thing we need to do here is to show our model how to minimize the error. To do that we need an optimization algorithm(optimizer). Once again, there are many kinds of optimizers all serving the same purpose but for the sake of keeping things simple but still meaningful we are going to use the most widely used and the one which many other optimization algorithms are based on. Behold the mighty Gradient Descent:\n",
    "\n",
    "<img src=\"Cost_v_weight.webp\" width=650 height=350 />\n",
    "Graphical representation of Gradient Descent | Source: Medium\n",
    "\n",
    "Doesn’t look as scary as it sounds, does it? Good news everybody, it is a relatively simple concept. By definition, the gradient is a fancy word for derivative, or the rate of change of a function.\n",
    "\n",
    "<img src=\"3Dgradient_descent.webp\" width=650 height=350 />\n",
    "3D representation of Gradient | Source: OReilly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let’s imagine our model is a ball. The surface represents the gradient(derivative) of the error. We want the ball to roll down the surface(descent) as low as possible in order to decrease the altitude(the error). Taking it to Math level — we need to reach a global(or at least a good enough local) minimum.\n",
    "\n",
    "In order to make the ball move though, we need to update our parameters at a certain rate — called learning rate. This is a predefined parameter that we pass to our model before we run it. Those kind of parameters are called <em>hyperparameters</em> and have a huge role in our model’s performance. Here is what I mean:\n",
    "\n",
    "<img src=\"learning_rate.webp\" width=650 height=350 />\n",
    "Significance of Learning Rate | Source: analyticsvidhya.com\n",
    "\n",
    "If we choose a learning rate that is too big the parameters will change drastically and we might skip the minimum. If our learning rate is too small on the other hand, it will take too much time and hence computing power to reach a satisfying result. That’s why tuning this parameter by testing the model with different values of the learning rate is rather important. It is highly recommended to start with a learning rate of 0.1 or 0.01 and start tuning from there on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to back(propagation)\n",
    "\n",
    "Now we need to update the model’s parameters layer by layer by passing the appropriate data to the backpropagation methods. The backpropagation takes two parameters — output error and the learning rate. Output error is calculated either as the result of the derivative of the cost function or as the result of the backpropagation of the previous layer(if looked from point B to point A) — as written above, the backward propagation should give as a result the derivative of the forward propagation function. By doing this each layer shows its predecessor its error.\n",
    "\n",
    "So in other words if for some reason we had a Sine Layer it would look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(Layer):\n",
    "  \n",
    "  def forward_propagation(self, input_data):\n",
    "    return np.sin(input_data)\n",
    "    \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "  \n",
    "    # some update logic based on the output_error and learning_rate\n",
    "    \n",
    "    return np.cos(output_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve got the two parameters needed, the backpropagation should update the layers weights(if such are present). Since every type of layer is different, it defines its own logic for parameter tuning — something which we will cover in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up Gradient Descent\n",
    "\n",
    "When each layer’s backpropagation is complete and our train arrives at point A, it takes the next sample(or set of samples) and starts its course through the hidden layers’ forward propagation functions once again — only this time, they should perform a bit better. This process continues on and on until training is completed and/or an error minimum has been reached.\n",
    "\n",
    "Now that we’ve explained all the theory behind gradient descent, here is how it should look in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is just an example without inputs defined...\n"
     ]
    }
   ],
   "source": [
    "#This is just an example it will break without inputs!\n",
    "try:\n",
    "#####    \n",
    "    for j in range(samples_length):\n",
    "      output = x_train[j]\n",
    "      \n",
    "      for layer in layers:\n",
    "        output = layer.forward_propagation(output)\n",
    "    \n",
    "      error = loss_prime(y_train[j], output)\n",
    "      \n",
    "      for layer in reversed(layers):\n",
    "          error = layer.backward_propagation(error, learning_rate)\n",
    "#####\n",
    "except:\n",
    "    print(\"this is just an example without inputs defined...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this snippet gives much more clearance on the algorithm itself. The only thing that we haven’t fully covered yet is what types of layers we can use in a network and how to implement them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Layers\n",
    "\n",
    "As though there are many kinds of layers to choose from for a starter, the infamous Fully-Connected Layer is undoubtedly the best choice.\n",
    "### Fully-Connected\n",
    "\n",
    "The Fully-Connected Layer is the most widely used class type. Its principles of work are based on the Rosenblatt model and are as follow:\n",
    "\n",
    "1. Every single perceptron from the previous layer is linked to every single perceptron of this layer.\n",
    "2. Each link has a weighted value(weight).\n",
    "3. A bias (offset) is added to the results.\n",
    "4. The layer’s weights are held in a 2D array with size m x n (where m is the number of perceptrons in the previous layer and n is the number of perceptrons in this layer). They are initialized as random values.\n",
    "5. The layer’s bias is held in a 1D array with size n. It is initialized as random values.\n",
    "\n",
    "<img src=\"fully_connected_layer.webp\" width=350 height=350 />\n",
    "Visual representation of Fully-Connected (FC) Layer | Source: cs231n.github.io\n",
    "\n",
    "Now let’s head to our implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(Layer):\n",
    "  \n",
    "  def __init__(self, output_size):    \n",
    "    self.output_size = output_size\n",
    "    self.bias = np.random.rand(1, self.output_size) - 0.5\n",
    "    \n",
    "    self.weights = None\n",
    "    \n",
    "  def forward_propagation(self, input_data):\n",
    "    if self.weights is None:\n",
    "      self.initialize(input_data)\n",
    "    \n",
    "    self.input = input_data.reshape((1, -1)) # ensure data is a 1D array\n",
    "    self.output = np.dot(self.input, self.weights) + self.bias # Multiply the links by their weights\n",
    "    \n",
    "    return self.output\n",
    "  \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    input_error = np.dot(output_error, self.weights.T) # calculate derivative of the forward propagation\n",
    "    weights_error = np.dot(self.input.T, output_error) # calculate the weights error\n",
    "    \n",
    "    self.weights -= learning_rate * weights_error # update the weights\n",
    "    self.bias -= learning_rate * output_error # update the error\n",
    "    \n",
    "    return input_error\n",
    "  \n",
    "  def initialize(self, input_data):        \n",
    "    self.weights = np.random.rand(input_data.size, self.output_size) - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the implementation of our to methods here is not something too complicated as long as you know basic linear algebra. And although relatively simple, this is a completely useful and optimized layer implementation which we will easily put to use later.\n",
    "\n",
    "The only problem with Fully-Connected Layers though is that they are <strong>linear</strong>. In fact, most layers have completely linear logic. A linear function is a polynomial of one degree. Using only such functions hinders the model’s ability to learn complex functional mappings, hence, learning is limited. That’s why(by convention) it is good to add non-linear functionality after every linear layer using activation layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer\n",
    "\n",
    "Activation layers are just like any other type of layer except they don’t have weights but use a non-linear function over the input instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "  \n",
    "  def __init__(self, activation, activation_prime):\n",
    "    self.activation = activation\n",
    "    self.activation_prime = activation_prime\n",
    "    \n",
    "  def forward_propagation(self, input_data):\n",
    "    self.input = input_data\n",
    "    self.output = self.activation(self.input)\n",
    "    \n",
    "    return self.output\n",
    "  \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    return self.activation_prime(self.input, self.output) * output_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good example of such activation function is tanh which stands for hyperbolic tangent.\n",
    "<img src = \"tanh.webp\" width = 350 height = 350 />\n",
    "tanh compared to sinh and cosh | Source: Wikipedia\n",
    "\n",
    "Since we are going to need it when we begin building our model, we need to implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(X): # used for forward propagation\n",
    "  return np.tanh(X)\n",
    "\n",
    "def tanh_prime(X, output): # used for backpropagation\n",
    "  return 1 - np.tanh(X) ** 2 # derivative of tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our two most important layers implemented, let’s proceed to implementing the whole Neural Network class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Implementation\n",
    "\n",
    "There are several methods that need to be implemented\n",
    "\n",
    "* a <strong>constructor</strong> — here we need to pass the <em>hyperparameters</em> (learning rate and number of epochs — the number of times our network will run over the input dataset); initialization of necessary fields\n",
    "* <strong> add layer method</strong> — pass an instance of a layer; used for model construction; can (should) be used several times in order to add several layers;\n",
    "* <strong> use <em>cost function</em> method</strong> — specify the cost function to be used when training the model\n",
    "* <strong>fit method</strong> — a standard name for the method that performs the training process; here is where we will place the gradient descent snippet from earlier\n",
    "* <strong> predict method</strong> — a standard name for the method that is used to calculate results only; it is useful once the training process is complete\n",
    "\n",
    "And here goes the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "  def __init__(self):\n",
    "    self.layers = []\n",
    "    self.loss = None\n",
    "    self.loss_prime = None\n",
    "\n",
    "  def add(self, layer):\n",
    "    self.layers.append(layer)\n",
    "    return self\n",
    "\n",
    "  def use(self, loss, loss_prime):\n",
    "    self.loss = loss\n",
    "    self.loss_prime = loss_prime\n",
    "\n",
    "    return self\n",
    "\n",
    "  def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "    samples = len(x_train)\n",
    "\n",
    "    for i in range(epochs): # each epoch represents one iteration over all samples\n",
    "      err = 0\n",
    "\n",
    "      for j in range(samples): # our gradient descent logic from earlier in the article\n",
    "        output = x_train[j]\n",
    "        for layer in self.layers:\n",
    "          output = layer.forward_propagation(output)\n",
    "\n",
    "        err += self.loss(y_train[j], output)\n",
    "\n",
    "        error = self.loss_prime(y_train[j], output)\n",
    "        for layer in reversed(self.layers):\n",
    "            error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "      err /= samples\n",
    "      print('epoch %d/%d   error=%f' % (i+1, epochs, err))\n",
    "\n",
    "    return self\n",
    "\n",
    "  def predict(self, input_data):\n",
    "      samples = len(input_data)\n",
    "      result = []\n",
    "\n",
    "      for i in range(samples): # basically running the forward propagation of all layers to get the result\n",
    "          output = input_data[i]\n",
    "          for layer in self.layers:\n",
    "              output = layer.forward_propagation(output)\n",
    "          result.append(output)\n",
    "\n",
    "      return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed the return self statement being present at the end of every method. The reason I put this is that it allows us to do method chaining. If you are not sure what I am talking about, you are going to see a good example in a bit.\n",
    "\n",
    "Now let’s put it to work. We are going to use the <strong>MNIST</strong> database for classifying handwritten digits. You can download it from http://yann.lecun.com/exdb/mnist/, or you can easily import it from <strong>Keras</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the pixel values are represented in the range [0; 255], we are going to scale that down to a range of [0.0, 1.0] or binary.\n",
    "\n",
    "Another thing we did is we made the y(the results) be a little bit more convenient(note keras.utils.to_categorical). What it does is it represents the numeric result in a one-shot vector:\n",
    "\n",
    "5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "This is helpful because our network’s output layer is going to consist of 10 nodes, each holding an output value. Since the ideal case output would be a correct one-hot vector it is now easier for the cost function to do its job.\n",
    "\n",
    "Now let’s construct our first network by putting some FC and activation layers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30   error=0.222736\n",
      "epoch 2/30   error=0.099694\n",
      "epoch 3/30   error=0.083481\n",
      "epoch 4/30   error=0.072148\n",
      "epoch 5/30   error=0.063514\n",
      "epoch 6/30   error=0.055902\n",
      "epoch 7/30   error=0.049157\n",
      "epoch 8/30   error=0.042833\n",
      "epoch 9/30   error=0.037858\n",
      "epoch 10/30   error=0.033846\n",
      "epoch 11/30   error=0.030232\n",
      "epoch 12/30   error=0.027105\n",
      "epoch 13/30   error=0.024514\n",
      "epoch 14/30   error=0.022183\n",
      "epoch 15/30   error=0.020059\n",
      "epoch 16/30   error=0.018465\n",
      "epoch 17/30   error=0.017138\n",
      "epoch 18/30   error=0.016022\n",
      "epoch 19/30   error=0.015030\n",
      "epoch 20/30   error=0.014135\n",
      "epoch 21/30   error=0.013316\n",
      "epoch 22/30   error=0.012645\n",
      "epoch 23/30   error=0.012019\n",
      "epoch 24/30   error=0.011531\n",
      "epoch 25/30   error=0.011040\n",
      "epoch 26/30   error=0.010639\n",
      "epoch 27/30   error=0.010134\n",
      "epoch 28/30   error=0.009706\n",
      "epoch 29/30   error=0.009205\n",
      "epoch 30/30   error=0.008854\n"
     ]
    }
   ],
   "source": [
    "fc_net = NeuralNetwork()\n",
    "\n",
    "(fc_net\n",
    "  .add(FCLayer(100))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(FCLayer(50))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(FCLayer(10))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .use(mse, mse_prime)\n",
    "  .fit(x_train[0:1000], y_train[0:1000], epochs=30, learning_rate=0.1)\n",
    ")\n",
    "\n",
    "preds = fc_net.predict(x_test[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we use only the first 1000 samples is that it is going to run too long if we use all the samples. Using more samples in this case will give you better results, so you can try a bigger range if you have the time.\n",
    "\n",
    "Before we run this though, we need to add one more final touch — another pre-output activation function — Softmax. What it does is it normalizes an array with n elements in a probability distribution array consisting of n probabilities proportional to the exponentials of the input numbers, or simply put — calculates the probability that the sample matches a certain class.\n",
    "\n",
    "### softmax function: $\\mathrm{s}(z_i) = \\frac{e^{z_i}}{\\sum e^{z_j}}$\n",
    "\n",
    "And the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "  exps = np.exp(X - X.max())\n",
    "  return exps / np.sum(exps)\n",
    "\n",
    "def softmax_prime(X, output):\n",
    "  result = np.zeros(X.shape)\n",
    "\n",
    "  for i in range(len(output)):\n",
    "    for j in range(len(X)):\n",
    "      if i == j:\n",
    "        result = output[i] * (1 - X[i])\n",
    "      else: \n",
    "        result = -output[i] * X[j]\n",
    "    \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we used:\n",
    "\n",
    "## $\\frac {\\partial s_i}{\\partial z_j} = s_i \\frac {\\partial}{\\partial z_j} \\mathrm{log} s_i = s_i \\cdot (\\delta_{ij} - s_j) $ \n",
    "\n",
    "for the derivative. The derivation is here: https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1\n",
    "\n",
    "Let’s try it once again, only this time we are going to have the <strong>Softmax</strong> activation as our final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30   error=0.090076\n",
      "epoch 2/30   error=0.079921\n",
      "epoch 3/30   error=0.071615\n",
      "epoch 4/30   error=0.064268\n",
      "epoch 5/30   error=0.058992\n",
      "epoch 6/30   error=0.055396\n",
      "epoch 7/30   error=0.052729\n",
      "epoch 8/30   error=0.050661\n",
      "epoch 9/30   error=0.049039\n",
      "epoch 10/30   error=0.047714\n",
      "epoch 11/30   error=0.046599\n",
      "epoch 12/30   error=0.045631\n",
      "epoch 13/30   error=0.044790\n",
      "epoch 14/30   error=0.044066\n",
      "epoch 15/30   error=0.043420\n",
      "epoch 16/30   error=0.042847\n",
      "epoch 17/30   error=0.042340\n",
      "epoch 18/30   error=0.041893\n",
      "epoch 19/30   error=0.041488\n",
      "epoch 20/30   error=0.041115\n",
      "epoch 21/30   error=0.040775\n",
      "epoch 22/30   error=0.040444\n",
      "epoch 23/30   error=0.040169\n",
      "epoch 24/30   error=0.039918\n",
      "epoch 25/30   error=0.039686\n",
      "epoch 26/30   error=0.039471\n",
      "epoch 27/30   error=0.039275\n",
      "epoch 28/30   error=0.039089\n",
      "epoch 29/30   error=0.038912\n",
      "epoch 30/30   error=0.038745\n"
     ]
    }
   ],
   "source": [
    "fc_net = NeuralNetwork()\n",
    "\n",
    "(fc_net\n",
    "  .add(FCLayer(100))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(FCLayer(50))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(FCLayer(10))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(ActivationLayer(softmax, softmax_prime))\n",
    "  .use(mse, mse_prime)\n",
    "  .fit(x_train[0:2000], y_train[0:2000], epochs=30, learning_rate=.1)\n",
    ")\n",
    "\n",
    "preds = fc_net.predict(x_test[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve trained our data, let’s evaluate our final model.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Keep in mind that we have implemented a small model for educational purposes. It is not going to produce a quite high result. I would highly recommend playing around with it in order to get a better accuracy.\n",
    "\n",
    "In order to evaluate our results, we are going to use a simple utility from <strong>sklearn</strong> which shows as the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06067614 0.06068429 0.06552416 0.06083963 0.06793981 0.0606763\n",
      "  0.06067906 0.06135098 0.06068335 0.44094629]]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii = 99\n",
    "plt.imshow(x_test[ii,:,:,0])\n",
    "print(preds[ii])\n",
    "print(np.argmax(preds[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy | Normal net: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "normal_results = [np.argmax(sample) for sample in preds]\n",
    "\n",
    "print('Accuracy | Normal net: {}'.format(accuracy_score(y_test[:100], normal_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the basic of neural network construction we can proceed to the more advanced stuff…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks(CNN)\n",
    "\n",
    "The main problem with using FC layers for image recognition tasks is that it uses each pixel as a separate feature, which doesn’t seem quite right, given the fact that neural networks are aiming at replicating the human brain. And what helps our brain identify visual input is not just random points, but patterns of points instead. Here’s where processes called convolution and correlation come in handy.\n",
    "### Convolution and Correlation\n",
    "\n",
    "Convolution and correlation in image processing are almost identical processes having one small difference in their implementation. Both of them take an image I, produce a matrix O based on another matrix (called filter or feature map) F. Here is what I mean\n",
    "\n",
    "Let’s start with correlation:\n",
    "<img src = \"correlate_matrix.webp\" width = 650 height = 350 />\n",
    "Visual representation of Correlation | Source: My Late Night PowerPoint Creations\n",
    "<img src = \"correlate_matrix2.webp\" width = 650 height = 350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s explain what is happening. The filter is acting like a sliding window which goes through the array, step by step, sliding right until it reaches the end of the row. Then it slides down and starts at the beginning of the row. At each position we sum the dot product of the filter F and the respective window of the input image I. Each position represents a cell in the output O.\n",
    "\n",
    "### Now what about convolution?\n",
    "\n",
    "The only difference between correlation and convolution is that convolution works with the same filter F, only rotated 180 degrees.\n",
    "\n",
    "<img src = \"convolution.webp\" width = 650 height = 350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But how does that helps us?\n",
    "\n",
    "By using this sort of filters, going through our image we extract not only one pixel, but a whole sector of pixels, enabling our model to map more complex image features like lines and shapes.\n",
    "\n",
    "For example, if you give a convolution layer a cat image it will be able to recognize small features like nose and ears. Then by adding more convolution layers after that it may recognize features of a larger scale like a head or a tail.\n",
    "\n",
    "The way this works is having several filters per convolution layer, all initialized with random numbers. The goal behind this is to have each filter activate on different features(one features trains to detect the nose, other the eyes, etc.).\n",
    "\n",
    "Usually when dealing with multi-channel images(like RGB) your filters will be 3-dimensional and will have the depth equal to the image channels count. That way you only focus on the 2D process.\n",
    "\n",
    "#### Padding and Stride\n",
    "\n",
    "The problem with convolution and correlation is that the corner pixels don’t get much attention — they only get processed once. If you want to change that, you can add a padding.\n",
    "\n",
    "<img src = \"padding.webp\" width = 350 height = 350 />\n",
    "\n",
    "Now even the corners will be processed as much as the other parts of the image.\n",
    "\n",
    "Sometimes, however we don’t want to pay as much attention to each pixel(highly applicable when dealing with larger images). Having each filter go through every possible position is sometimes an overkill. That’s why we can configure a stride.\n",
    "\n",
    "The stride tells our filter how much it should slide when going to its next position. Having a stride of 2 will skip one position with each shift which reduces the size of the output and makes computation lighter.\n",
    "\n",
    "<img src = \"stride.webp\" width = 650 height = 350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Having no stride basically means having a stride of 1 — the filters cover every possible position without skipping</em>.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "First let’s list our parameters:\n",
    "\n",
    "* Filters Count — how many filters are we going to have in the layer\n",
    "* Filter Size — how big our filters will be\n",
    "* Padding — how much zero padding are we going to have(we are going to use a tuple format for this one (x, y), where x stands for column zero padding and y stands for row zero padding).\n",
    "* Stride — just a plain number showing how many positions should a filter move per slide\n",
    "\n",
    "NB! Because we are going to initialize our filters with random values, there is practically no difference between using correlation or convolution so we are going to use correlation for simplicity.\n",
    "\n",
    "Here’s a very iterative(for-loopy) approach on implementing a convolution layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLayerSlow(Layer):\n",
    "  \n",
    "  def __init__(self, filters_count, filter_shape, padding=(0, 0), stride=1):\n",
    "    self.filters_count = filters_count\n",
    "    self.filter_shape = filter_shape\n",
    "    self.stride = stride\n",
    "    self.padding = (padding[0], padding[1], 0)\n",
    "        \n",
    "    self.input_shape = None\n",
    "    self.input_depth = None\n",
    "\n",
    "    self.output_shape = None\n",
    "    self.weights = None\n",
    "   \n",
    "  def forward_propagation(self, input_data):\n",
    "    \n",
    "    if self.input_shape is None:\n",
    "      self.initialize(input_data)\n",
    "    \n",
    "    self.input = np.pad(input_data, ((self.padding[0], self.padding[0]), (self.padding[1], self.padding[1]), (self.padding[2], self.padding[2])), 'constant') \n",
    "    self.output = np.zeros(self.output_shape)\n",
    "\n",
    "    for filter in range(self.filters_count):\n",
    "       for channel in range(self.input_depth):\n",
    "        row_iteration = 0\n",
    "\n",
    "        for row in range(0, self.input_shape[0], self.stride):\n",
    "          col_iteration = 0\n",
    "\n",
    "          for col in range(0, self.input_shape[1], self.stride):        \n",
    "            if row + self.filter_shape[0] >= self.input_shape[0] or col + self.filter_shape[1] >= self.input_shape[1]:\n",
    "              continue\n",
    "\n",
    "            self.output[row_iteration, col_iteration, filter] += np.sum(self.input[row : row + self.filter_shape[0], col + self.filter_shape[1], channel] * self.weights[filter])    \n",
    "\n",
    "            col_iteration += 1\n",
    "\n",
    "          row_iteration += 1\n",
    "\n",
    "    return self.output\n",
    "    \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    in_error = np.zeros(self.input_shape)\n",
    "    dWeights = np.zeros((self.filters_count, self.filter_shape[0], self.filter_shape[1]))\n",
    "\n",
    "    for filter in range(self.filters_count):\n",
    "      for channel in range(self.input_depth):\n",
    "      \n",
    "        row_iteration = 0\n",
    "\n",
    "        for row in range(output_error.shape[0]):     \n",
    "          input_row_index = row * self.stride\n",
    "\n",
    "          for col in range(output_error.shape[1]):        \n",
    "            input_col_index = col * self.stride  \n",
    "\n",
    "            if input_row_index + self.filter_shape[0] >= self.input_shape[0] or input_col_index + self.filter_shape[1] >= self.input_shape[1]:\n",
    "              continue\n",
    "\n",
    "            in_error[input_row_index : input_row_index + self.filter_shape[0], input_col_index : input_col_index + self.filter_shape[1], channel] += self.weights[filter] * output_error[row, col, filter]\n",
    "            dWeights[filter] = self.input[row_iteration : row_iteration + self.filter_shape[0], input_col_index : input_col_index + self.filter_shape[1], channel] * output_error[row, col, filter]\n",
    "\n",
    "    self.weights -= learning_rate * dWeights\n",
    "    \n",
    "    return in_error\n",
    "  \n",
    "  def initialize(self, input_data):    \n",
    "      self.input_shape = input_data.shape\n",
    "      self.input_depth = self.input_shape[2]\n",
    "    \n",
    "      self.output_shape = (int((self.input_shape[0] - self.filter_shape[0] + 2 * self.padding[0]) / self.stride + 1), int((self.input_shape[1] - self.filter_shape[1] + 2 * self.padding[1]) / self.stride + 1), self.filters_count) # using a simple formula to calculate output size based on input size, padding and stride\n",
    "      self.weights = np.random.rand(self.filters_count, self.filter_shape[0], self.filter_shape[1]) - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though being a bit easier to understand, it is too slow because it lacks vectorization (uses for-loops instead of array-based operations). That’s why I dug around and found some very useful library methods that helped me optimize my layer:\n",
    "\n",
    "* <strong>skimage.util.view_as_windows</strong> — I used it to automatically get the positions where my filters should go instead of looping through them on my own.\n",
    "* <strong>np.tensordot</strong> — I used it to multiply the windows(which I got from the method mentioned above) with the filters.\n",
    "\n",
    "Unfortunately, I could not find an easy way to vectorize the calculation of in_error (the closest I got was using scipy.signal.convolve_2d, but it did not work with stride), until it occurred to me that vectorized operations are usually for loops written in a lower level language so I implemented my own method called convolve_2d_stride using Cython (a library which lets you easily integrate C code into Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of stderr:\n",
      "In file included from /Users/dik/.cache/ipython/cython/_cython_magic_fac6d93aae878f4df038e91009bfb7defc6fdd86.c:1216:\n",
      "In file included from /Users/dik/anaconda3/lib/python3.11/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /Users/dik/anaconda3/lib/python3.11/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /Users/dik/anaconda3/lib/python3.11/site-packages/numpy/core/include/numpy/ndarraytypes.h:1929:\n",
      "/Users/dik/anaconda3/lib/python3.11/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: \"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      " ^\n",
      "1 warning generated."
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "cimport numpy as np\n",
    "\n",
    "cpdef np.ndarray convolve_2d_stride(np.ndarray data, np.ndarray filter, np.ndarray result, int stride):\n",
    "  \n",
    "  cdef int output_rows_count = data.shape[0]\n",
    "  cdef int output_cols_count = data.shape[1]\n",
    "  \n",
    "  cdef int filter_rows_count = data.shape[0]\n",
    "  cdef int filter_cols_count = data.shape[1]\n",
    "  \n",
    "  cdef int result_rows_count = data.shape[0]\n",
    "  cdef int result_cols_count = data.shape[1]\n",
    "\n",
    "  cdef int row = 0\n",
    "  cdef int col = 0\n",
    "  \n",
    "  cdef int input_row_index = 0\n",
    "  cdef int input_col_index = 0\n",
    "    \n",
    "  for row in range(output_rows_count):     \n",
    "    input_row_index = row * stride\n",
    "\n",
    "    for col in range(output_cols_count):        \n",
    "      input_col_index = col * stride  \n",
    "\n",
    "      if input_row_index + filter_rows_count >= result_rows_count or input_col_index + filter_cols_count >= result_cols_count:\n",
    "        continue\n",
    "\n",
    "      result[input_row_index : input_row_index + result_rows_count, input_col_index : input_col_index + filter_cols_count] += filter * data[row, col]\n",
    "      \n",
    "  return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info on Cython please visit their documentation (https://cython.readthedocs.io/en/latest/).\n",
    "\n",
    "Now that we have all our puzzle pieces on our table, let’s assemble our optimized convolution layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLayer(Layer):\n",
    "  \n",
    "  def __init__(self, filters_count, filter_shape, padding=(0, 0), stride=1):\n",
    "    self.filters_count = filters_count\n",
    "    self.filter_shape = filter_shape\n",
    "    self.stride = stride\n",
    "    self.padding = (padding[0], padding[1], 0)\n",
    "        \n",
    "    self.input_shape = None\n",
    "    self.input_depth = None\n",
    "\n",
    "    self.output_shape = None\n",
    "    self.weights = None\n",
    "    \n",
    "  def forward_propagation(self, input_data):\n",
    "    \n",
    "    if self.input_shape is None:\n",
    "      self.initialize(input_data)\n",
    "    \n",
    "    self.input = np.pad(input_data, ((self.padding[0], self.padding[0]), (self.padding[1], self.padding[1]), (self.padding[2], self.padding[2])), 'constant') \n",
    "    self.output = np.zeros(self.output_shape)\n",
    "\n",
    "    for channel in range(self.input_depth):\n",
    "      windows = skimage.util.view_as_windows(self.input[:, :, channel], self.filter_shape, self.stride)\n",
    "      \n",
    "      for filter in range(self.filters_count):\n",
    "        self.output[:, :, filter] += np.tensordot(windows, self.weights[filter], axes=((2,3),(0,1)))\n",
    "\n",
    "    return self.output\n",
    "    \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    in_error = np.zeros(self.input_shape)\n",
    "    dWeights = np.zeros((self.filters_count, self.filter_shape[0], self.filter_shape[1]))\n",
    "\n",
    "    for channel in range(self.input_depth):\n",
    "      \n",
    "      windows = skimage.util.view_as_windows(self.input[:, :, channel], self.filter_shape, self.stride)\n",
    "      \n",
    "      for filter in range(self.filters_count):\n",
    "        in_error[:, :, channel] += convolve_2d_stride(output_error, self.weights[filter], in_error[:, :, channel], self.stride) # here we use the cython function from earlier\n",
    "        dWeights  = np.tensordot(windows, output_error[:, :, filter], axes=((0,1),(0,1)))\n",
    "  \n",
    "    self.weights -= learning_rate * dWeights\n",
    "    \n",
    "    return in_error\n",
    "  \n",
    "  def initialize(self, input_data):    \n",
    "      self.input_shape = input_data.shape\n",
    "      self.input_depth = self.input_shape[2]\n",
    "    \n",
    "      self.output_shape = (int((self.input_shape[0] - self.filter_shape[0] + 2 * self.padding[0]) / self.stride + 1), int((self.input_shape[1] - self.filter_shape[1] + 2 * self.padding[1]) / self.stride + 1), self.filters_count)        \n",
    "      self.weights = np.random.rand(self.filters_count, self.filter_shape[0], self.filter_shape[1]) - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of optimization, the next set of layers that we will look at will help us save our GPUs from melting.\n",
    "Pooling Layers\n",
    "\n",
    "The idea behind pooling layers is to reduce the spatial size of the output of previous convolution layers. This helps our model for two reasons:\n",
    "\n",
    "1. It lowers down the computational power needed.\n",
    "2. It creates a lower resolution version of the input. This process is also called down-sampling. The reason this helps is Convolution layers’s filters are often bound to an exact position in the image. Having a small movement or distortion may result in a different output which is not desirable. Down-sampled images still contain the larger structural features, only excluding fine details that may hinder the model’s performance.\n",
    "\n",
    "An alternative to down-sampling that one can use to solve this problem is use a larger stride in the Convolution layer on the first place.\n",
    "\n",
    "The usual pattern met in most CNN models is as follows:\n",
    "\n",
    "* Convolution Layer\n",
    "* Activation Layer\n",
    "* Pooling Layer\n",
    "\n",
    "<img src=\"CNN_layers.webp\" width = 650 height = 350 />\n",
    "\n",
    "A typical CNN pattern | Source: jefkine.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle of work\n",
    "\n",
    "The way pooling works is somewhat similar to convolution and correlation. Once again we have a window(called pool) which slides over our input. The pool however does not contain any data like the filter/feature map did. When a pool moves in a position it calculates a result based only on the values in this position(like average or max).\n",
    "\n",
    "To help you understand how it works we are going to implement the most widely-used type — Max Pooling Layer.\n",
    "### Max Pooling Layer\n",
    "\n",
    "The idea is simple — when the pool slides to a position, the maximum value in that position is stored in the output.\n",
    "\n",
    "<img src = \"max_pooling_layer.webp\" width = 650 height = 350 />\n",
    "Visual representation of Max Pooling | Source: My Late Night PowerPoint Creations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "The list here is a lot simpler than the one for Convolution layer\n",
    "\n",
    "* Pool Shape— the shape of the pool, described in a tuple, a good default is (2, 2)\n",
    "* Stride — same as in convolution, a good default is 2(most of the cases it is good to match the dimensions of the pool)\n",
    "\n",
    "### Implementation\n",
    "\n",
    "It is a good idea to implement a base class once again, since some operation are the same for all pooling layers(like initialization for instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingLayer(Layer):\n",
    "  \n",
    "  def __init__(self, pool_shape=(2,2), stride=2):\n",
    "    self.pool_shape = pool_shape\n",
    "    self.stride = stride\n",
    "    self.padding = (int((self.pool_shape[0] - self.stride) / 2), int((self.pool_shape[1] - self.stride) / 2), 0)\n",
    "        \n",
    "    self.input_shape = None\n",
    "    self.input_depth = None\n",
    "    \n",
    "    self.output_shape = None\n",
    "    self.weights = None\n",
    "    \n",
    "  def forward_propagation(self, input):\n",
    "    raise NotImplementedError\n",
    "    \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    raise NotImplementedError\n",
    "    \n",
    "  def initialize(self, input_data):    \n",
    "    \n",
    "    self.input_shape = input_data.shape\n",
    "    self.input_depth = self.input_shape[2]\n",
    "    \n",
    "    self.output_shape = (int((self.input_shape[0] - self.pool_shape[0] + 2 * self.padding[0]) / self.stride + 1), int((self.input_shape[1] - self.pool_shape[1] + 2 * self.padding[1]) / self.stride + 1), self.input_depth)            \n",
    "    self.weights = np.random.rand(self.pool_shape[0], self.pool_shape[1], self.input_depth) - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here goes the <strong>Max Pooling</strong>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer(PoolingLayer):  \n",
    "  \n",
    "  def forward_propagation(self, input_data):\n",
    "    \n",
    "    if self.input_shape is None:\n",
    "      self.initialize(input_data)\n",
    "    \n",
    "    self.input = np.pad(input_data, ((self.padding[0], self.padding[0]), (self.padding[1], self.padding[1]), (self.padding[2], self.padding[2])), 'constant')\n",
    "    self.output = np.zeros(self.output_shape)\n",
    "\n",
    "    for layer in range(self.input_depth):\n",
    "        row_iteration = 0\n",
    "\n",
    "        for row in range(0, self.input_shape[0], self.stride):\n",
    "          col_iteration = 0\n",
    "\n",
    "          for col in range(0, self.input_shape[1], self.stride):        \n",
    "            if row + self.pool_shape[0] >= self.input_shape[0] or col + self.pool_shape[1] >= self.input_shape[1]:\n",
    "              continue\n",
    "\n",
    "            self.output[row_iteration, col_iteration, layer] = np.amax(self.input[row : row + self.pool_shape[0], col : col + self.pool_shape[1], layer])\n",
    "\n",
    "            col_iteration += 1\n",
    "\n",
    "          row_iteration += 1\n",
    "\n",
    "    return self.output\n",
    "    \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    in_error = np.zeros(self.input.shape)\n",
    "    \n",
    "    for layer in range(self.input_depth):\n",
    "\n",
    "      row_iteration = 0\n",
    "\n",
    "      for row in range(output_error.shape[0]):     \n",
    "        input_row_index = row * self.stride\n",
    "\n",
    "        for col in range(output_error.shape[1]):        \n",
    "          input_col_index = col * self.stride  \n",
    "\n",
    "          if input_row_index + self.pool_shape[0] >= self.input_shape[0] or input_col_index + self.pool_shape[1] >= self.input_shape[1]:\n",
    "            continue\n",
    "            \n",
    "          pool = self.input[input_row_index : input_row_index + self.pool_shape[0], input_col_index : input_col_index + self.pool_shape[1], layer]\n",
    "          mask = (pool == np.max(pool))\n",
    "          in_error[input_row_index : input_row_index + self.pool_shape[0], input_col_index : input_col_index + self.pool_shape[1], layer] = mask * output_error[row, col, layer]\n",
    "    \n",
    "    return in_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I strongly encourage you to try and implement <strong>Average Pooling Layer</strong> by yourself.\n",
    "\n",
    "Before we build our first CNN model, we need to reformat our data so that it can be used by other layers like Fully-Connected. This is needed because the last non-activation layer should always be Fully-Connected when we are solving a classification task. And because Fully-Connected would be a mess if its input is anything else then a 1D array, we must flatten(convert N-D array to 1D array) the data first.\n",
    "### Flatten Layer\n",
    "\n",
    "This is probably the simplest layer to implement. Our forward propagation needs to flatten the input and the backpropagation needs to reformat it back to its initial form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "  \n",
    "  def forward_propagation(self, input_data):\n",
    "    self.input_shape = input_data.shape\n",
    "    return input_data.flatten()\n",
    "  \n",
    "  def backward_propagation(self, output_error, learning_rate):\n",
    "    return output_error.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s build our first CNN…\n",
    "### CNN Model\n",
    "\n",
    "We are going to build a simple CNN using all the layers we implemented in this article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30   error=0.084884\n",
      "epoch 2/30   error=0.062682\n",
      "epoch 3/30   error=0.054266\n",
      "epoch 4/30   error=0.050843\n",
      "epoch 5/30   error=0.048875\n",
      "epoch 6/30   error=0.047544\n",
      "epoch 7/30   error=0.046537\n",
      "epoch 8/30   error=0.045725\n",
      "epoch 9/30   error=0.045046\n",
      "epoch 10/30   error=0.044488\n",
      "epoch 11/30   error=0.044010\n",
      "epoch 12/30   error=0.043602\n",
      "epoch 13/30   error=0.043242\n",
      "epoch 14/30   error=0.042922\n",
      "epoch 15/30   error=0.042637\n",
      "epoch 16/30   error=0.042372\n",
      "epoch 17/30   error=0.042119\n",
      "epoch 18/30   error=0.041890\n",
      "epoch 19/30   error=0.041677\n",
      "epoch 20/30   error=0.041476\n",
      "epoch 21/30   error=0.041292\n",
      "epoch 22/30   error=0.041119\n",
      "epoch 23/30   error=0.040950\n",
      "epoch 24/30   error=0.040801\n",
      "epoch 25/30   error=0.040652\n",
      "epoch 26/30   error=0.040507\n",
      "epoch 27/30   error=0.040373\n",
      "epoch 28/30   error=0.040245\n",
      "epoch 29/30   error=0.040126\n",
      "epoch 30/30   error=0.040012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv_net = NeuralNetwork()\n",
    "\n",
    "(conv_net\n",
    "  .add(ConvolutionalLayer(filter_shape=(3, 3), filters_count=5, stride=2, padding=(1,1)))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(MaxPoolingLayer(pool_shape=(2, 2)))\n",
    "  .add(FlattenLayer())\n",
    "  .add(FCLayer(100))\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(FCLayer(50))  \n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(FCLayer(10))\n",
    "  .add(FlattenLayer())\n",
    "  .add(ActivationLayer(tanh, tanh_prime))\n",
    "  .add(ActivationLayer(softmax, softmax_prime))\n",
    "  .use(mse, mse_prime)\n",
    "  .fit(x_train[0:4000], y_train[0:4000], epochs=30, learning_rate=0.1)\n",
    ")\n",
    "\n",
    "conv_preds = conv_net.predict(x_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s see how well it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy | Conv Net: 0.95\n"
     ]
    }
   ],
   "source": [
    "conv_results = [np.argmax(sample) for sample in conv_preds]\n",
    "\n",
    "print('Accuracy | Conv Net: {}'.format(accuracy_score(y_test[:100], conv_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should perform better than our normal net, although it can actually achieve much higher results if you play around with it and have the patience to wait for the training process to finish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at a *very* brief summary of Large Language Models (LLMS):\n",
    "### [3Blue1Brown Youtube video](https://www.youtube.com/watch?v=LPZh9BOjkQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
